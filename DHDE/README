%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% A Unified Approach of Multi-scale Deep and Hand-crafted Features
% for Defocus Estimation
%
% Jinsun Park, Yu-Wing Tai, Donghyeon Cho and In So Kweon
%
% CVPR 2017
%
% Please feel free to contact if you have any problems.
% 
% E-mail : Jinsun Park (zzangjinsun@gmail.com)
%          Robotics and Computer Vision Lab., EE,
%          KAIST, Republic of Korea
% Project Page : https://github.com/zzangjinsun/DHDE_CVPR17/
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

1. Training
 1) Prepare training dataset. They should be placed individually under 'data/training/%04d'.

    For example, there are currently 3 images (from ImageNet[5]) in 
    'data/training/0001', 'data/training/0002' and 'data/training/0003'.

 2) Run 'DHDE_feature_extraction.m' for feature extraction.
    (Please adjust parameters adequately.)
    It will generate {dbDCT, dbGRD, dbSVD, dbIMG, log.txt} in each folder.
    'log.txt' contains number of extracted features and elapsed time.

 3) Run 'DHDE_db_generation.m' for train/validation db generation.

 4) Create 'logs' and 'models' directory.

 5) Run 'DHDE_train.sh' to start training. (Change TOOLS to your caffe path.)
    log files will be saved in 'logs' and snapshots will be saved in 'models'.



2. Defocus estimation
 1) Run 'DHDE_compile_jointWMF.m' in 'subfunctions/JointWMF'.
    (Please adjust library path adequately.)
    It will generate 'mexJointWMF.mexa64' in the same folder.

 2) Run 'DHDE_defocus_estimation.m'.
    (Please adjust parameters adequately.)

 3) Outputs can be found in 'data/defocus/%04d/multiscale'.
 
 
 
Notes
 - External dependencies (Joint WMF [6] and Rolling Guidance Filter [7]) are
   included for your convenience. They can be downloaded from their websites.

 - Please carefully adjust library path for mex compilation of JointWMF.
 
 - Test images are from Blur Detection Dataset [2].



References

[1] Shi, Jianping, et al. "Break ames room illusion: depth from general single images."
    ACM Transactions on Graphics (TOG) 34.6 (2015): 225.

[2] Shi, Jianping, Li Xu, and Jiaya Jia. "Discriminative blur detection features."
    Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2014.

[3] Shi, Jianping, Li Xu, and Jiaya Jia. "Just noticeable defocus blur detection and estimation."
    Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015.

[4] Zhuo, Shaojie, and Terence Sim. "Defocus map estimation from a single image."
    Pattern Recognition 44.9 (2011): 1852-1858.

[5] Russakovsky, Olga, et al. "Imagenet large scale visual recognition challenge."
    International Journal of Computer Vision 115.3 (2015): 211-252.

[6] Zhang, Qi, Li Xu, and Jiaya Jia. "100+ times faster weighted median filter (WMF)."
    Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2014.

[7] Zhang, Qi, et al. "Rolling guidance filter." European Conference on Computer Vision.
    Springer International Publishing, 2014.
